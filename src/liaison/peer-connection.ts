import { WS_OPEN_STATE } from '@cve-ts/dictionary'

import audio from '../audio'
import video from '../video/element'

import { getBooleanAttribute, player } from '../player/custom-element'
import { emitDebugEvent } from '../player/emitter'
import {
  createDataChannel,
  setupDataChannelCallbacks,
  updateDataChannel,
} from './data-channel'
import { ws } from './web-socket'

interface SdpConstraints {
  /** If you don't need audio you can get improved latency by turning this off. */
  offerToReceiveAudio: boolean
  offerToReceiveVideo: boolean
  voiceActivityDetection: boolean
}

export let pc: RTCPeerConnection | undefined

export function createOffer(config: RTCConfiguration) {
  if (pc) {
    pc.close()
    pc = undefined
  }
  pc = new RTCPeerConnection(config)
  setupPeerConnection(pc)

  console.log(
    '%c[pc]',
    'background: cyan; color: black',
    'Created ===> ',
    config
  )

  setupTransceiversAsync(pc).finally(() => {
    const init: RTCDataChannelInit = {
      ordered: false,
    }
    console.log(
      '%c[pc]',
      'background: cyan; color: black',
      'Setup Transceivers Async ===> ',
      init
    )
    updateDataChannel(createDataChannel(pc!, 'cirrus', init))
    // Handle Create Offer
    const sdpConstraints: SdpConstraints = {
      offerToReceiveAudio: true,
      offerToReceiveVideo: true,
      voiceActivityDetection: false,
    }
    pc?.createOffer(sdpConstraints).then((offer) => {
      console.log(
        '%c[pc]',
        'background: cyan; color: black',
        'Offer Created ===> ',
        offer
      )
      // Munging is where we modifying the sdp string to set parameters that are not exposed to the browser's WebRTC API
      mungeSDP(offer)

      // Set our munged SDP on the local peer connection so it is "set" and will be send across
      pc?.setLocalDescription(offer)
      onWebRtcOffer(offer)
    })
  })
}

function mungeSDP(offer: RTCSessionDescriptionInit) {
  let audioSDP = ''

  // set max bitrate to highest bitrate Opus supports
  audioSDP += 'maxaveragebitrate=510000;'

  if (getBooleanAttribute('use-mic')) {
    // set the max capture rate to 48khz (so we can send high quality audio from mic)
    audioSDP += 'sprop-maxcapturerate=48000;'
  }

  // Force mono or stereo based on whether ?forceMono was passed or not
  audioSDP += getBooleanAttribute('force-mono-audio')
    ? 'sprop-stereo=0;stereo=0;'
    : 'sprop-stereo=1;stereo=1;'

  // enable in-band forward error correction for opus audio
  audioSDP += 'useinbandfec=1'

  // We use the line 'useinbandfec=1' (which Opus uses) to set our Opus specific audio parameters.
  offer.sdp = offer?.sdp?.replace('useinbandfec=1', audioSDP)

  console.log(
    '%c[pc]',
    'background: cyan; color: black',
    'munge SDP ===> ',
    offer
  )
}

export function onWebRtcAnswer(webRTCData: RTCSessionDescriptionInit) {
  console.log(
    '%c[pc]',
    'background: cyan; color: black',
    'WebRTC answer ===> ',
    webRTCData
  )
  // Receive Answer
  pc?.setRemoteDescription(webRTCData)

  // Check every 1 second
  emitDebugEvent('stats', 1000)
}

function onWebRtcCandidate(candidate: RTCIceCandidate) {
  if (ws?.readyState === WS_OPEN_STATE) {
    console.log(
      '%c[pc]',
      'background: cyan; color: black',
      'WebRTC ICE Candidate ===> ',
      candidate
    )
    ws.send(
      JSON.stringify({
        type: 'iceCandidate',
        candidate,
      })
    )
  }
}

export function onWebRtcIce(init?: RTCIceCandidateInit) {
  let candidate = new RTCIceCandidate(init)

  console.log(
    '%c[pc]',
    'background: pink; color: black',
    'UE WebRTC ICE ===> ',
    '| Type=',
    candidate.type,
    '| Protocol=',
    candidate.protocol,
    '| Address=',
    candidate.address,
    '| Port=',
    candidate.port,
    '|'
  )

  // if forcing TURN, reject any candidates not relay
  if (player?.getAttribute('force-turn') !== null) {
    // check if no relay address is found, if so, we are assuming it means no TURN server
    if (candidate.candidate.indexOf('relay') < 0) {
      console.warn(
        '%c[pc]',
        'background: cyan; color: black',
        'Dropping candidate because it was not TURN relay.',
        '| Type=',
        candidate.type,
        '| Protocol=',
        candidate.protocol,
        '| Address=',
        candidate.address,
        '| Port=',
        candidate.port,
        '|'
      )
      return
    }
  }

  pc?.addIceCandidate(candidate).catch(function (e) {
    console.log(
      '%c[pc]',
      'background: red; color: black',
      'Failed to add ICE candidate ===> ',
      e
    )
  })
}

function onWebRtcOffer(offer?: RTCSessionDescriptionInit) {
  if (ws?.readyState === WS_OPEN_STATE) {
    console.log(
      '%c[pc]',
      'background: cyan; color: black',
      'WebRTC offer ===> ',
      offer
    )
    const offerStr = JSON.stringify(offer)
    ws.send(offerStr)
  }
}

const availableVideoStreams: Map<string, MediaStream> = new Map()
function setupPeerConnection(pc: RTCPeerConnection) {
  pc.ontrack = (e: RTCTrackEvent) => {
    if (e.track.kind == 'audio') {
      const audioMediaStream: MediaStream = e.streams[0]
      // do nothing the video has the same media stream as the audio track we have here (they are linked)
      if (video.srcObject == audioMediaStream) {
        return
      }
      // video element has some other media stream that is not associated with this audio track
      else if (video.srcObject !== audioMediaStream) {
        audio.srcObject = audioMediaStream
      }
      return
    } else if (e.track.kind == 'video') {
      for (const s of e.streams) {
        if (!availableVideoStreams.has(s.id)) {
          availableVideoStreams.set(s.id, s)
        }
      }

      video.srcObject = e.streams[0]

      // All tracks are added "muted" by WebRTC/browser and become unmuted when media is being sent
      e.track.onunmute = () => {
        video.srcObject = e.streams[0]
        // onNewVideoTrack?.(e.streams)
      }
    }
  }
  pc.onicecandidate = (e: RTCPeerConnectionIceEvent) => {
    let candidate = e.candidate
    if (candidate && candidate.candidate) {
      console.log(
        '%c[pc]',
        'background: violet; color: black',
        'Browser WebRTC ICE ===> ',
        '| Type=',
        candidate.type,
        '| Protocol=',
        candidate.protocol,
        '| Address=',
        candidate.address,
        '| Port=',
        candidate.port,
        '|'
      )
      onWebRtcCandidate(candidate)
    }
  }
  pc.ondatachannel = (e: RTCDataChannelEvent) => {
    console.log(
      '%c[pc]',
      'background: cyan; color: black',
      'Data Channel ===> ',
      e
    )
    // This is the primary data channel code path when we are "receiving"
    updateDataChannel(e.channel)
    setupDataChannelCallbacks(e.channel)
  }
}

async function setupTransceiversAsync(pc: RTCPeerConnection) {
  let hasTransceivers = pc.getTransceivers().length > 0

  // Setup a transceiver for getting UE video
  pc.addTransceiver('video', { direction: 'recvonly' })

  // Setup a transceiver for sending mic audio to UE and receiving audio from UE
  const useMic = getBooleanAttribute('use-mic')
  if (!useMic) {
    pc.addTransceiver('audio', { direction: 'recvonly' })
  } else {
    let audioSendOptions = useMic
      ? {
          autoGainControl: false,
          channelCount: 1,
          echoCancellation: false,
          latency: 0,
          noiseSuppression: false,
          sampleRate: 48000,
          sampleSize: 16,
          volume: 1.0,
        }
      : false

    // Note using mic on android chrome requires SSL or chrome://flags/ "unsafely-treat-insecure-origin-as-secure"
    const stream = await navigator.mediaDevices.getUserMedia({
      video: false,
      audio: audioSendOptions,
    })
    if (stream) {
      if (hasTransceivers) {
        for (let transceiver of pc.getTransceivers()) {
          if (
            transceiver &&
            transceiver.receiver &&
            transceiver.receiver.track &&
            transceiver.receiver.track.kind === 'audio'
          ) {
            for (const track of stream.getTracks()) {
              if (track.kind && track.kind == 'audio') {
                transceiver.sender.replaceTrack(track)
                transceiver.direction = 'sendrecv'
              }
            }
          }
        }
      } else {
        for (const track of stream.getTracks()) {
          if (track.kind && track.kind == 'audio') {
            pc.addTransceiver(track, { direction: 'sendrecv' })
          }
        }
      }
    } else {
      pc.addTransceiver('audio', { direction: 'recvonly' })
    }
  }
}

export function updatePeerConnection(connection?: RTCPeerConnection) {
  pc = connection
}
